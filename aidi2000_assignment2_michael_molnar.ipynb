{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "flying-italy",
   "metadata": {},
   "source": [
    "## AIDI 2000 - Applied Machine Learning \n",
    "### Assignment 2 - Machine Translation\n",
    "\n",
    "#### Michael Molnar (100806823)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-louisiana",
   "metadata": {},
   "source": [
    "For this assignment I will build an Encoder-Decoder deep learning model to perform machine translation from French to English.\n",
    "\n",
    "Steps:\n",
    "- Load and examine the dataset\n",
    "- Perform pre-processing \n",
    "- Build and train the model\n",
    "- Evaluate the model on the testing dataset \n",
    "- Examine the model's predictions on training and testing data\n",
    "- Save the model and tokenizers\n",
    "- Use the model to make predictions on new French sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-conversation",
   "metadata": {},
   "source": [
    "#### Importing Necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "industrial-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-supervision",
   "metadata": {},
   "source": [
    "#### Loading and Examining the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-operator",
   "metadata": {},
   "source": [
    "I will be working with the English - French dataset provided on the page, \"Tab-delimited Bilingual Sentence Pairs\", frm the Tatoeba Project.  The dataset is available for download at http://www.manythings.org/anki/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prime-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into memory\n",
    "file = open('Data/fra.txt', mode='rt', encoding='utf-8')\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-elements",
   "metadata": {},
   "source": [
    "From the notes on the website, the data is in the form: \n",
    "\n",
    "English + TAB + The Other Language + TAB + Attribution\n",
    "\n",
    "I will keep only the first two elments - the English and French phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "guided-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data by line break \n",
    "lines = text.strip().split('\\n')\n",
    "# Split each line by tabs \n",
    "rows = [line.split('\\t')[:2] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "related-toilet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Go.', 'Va !'], ['Go.', 'Marche.'], ['Go.', 'Bouge !']]\n"
     ]
    }
   ],
   "source": [
    "# View a couple rows\n",
    "print(rows[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fixed-south",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\", \"Si quelqu'un qui ne connaît pas vos antécédents dit que vous parlez comme un locuteur natif, cela veut dire qu'il a probablement remarqué quelque chose à propos de votre élocution qui lui a fait prendre conscience que vous n'êtes pas un locuteur natif. En d'autres termes, vous ne parlez pas vraiment comme un locuteur natif.\"]\n"
     ]
    }
   ],
   "source": [
    "# View the last row\n",
    "print(rows[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-fisher",
   "metadata": {},
   "source": [
    "I can see that the first entry in each row is the English word or phrase, and the second entry is the French translation.  I can see the presence of capital letters and punctuations.  These, and other non-alphabetic characters, will be removed as part of the data pre-processing stage.  The phrases range from a single word to multiple sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "front-jesus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185583"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows \n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-cooler",
   "metadata": {},
   "source": [
    "There are over 185,000 sequence pairs in this dataset.  As I progressed through the code, I ran into memory issues due to the size.  As such, I will select the first 50,000 rows and use these for this assignment.  The length of sequences increases as you get further into the dataset, so these will be mostly shorter sequences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "embedded-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only the first 50,000 rows\n",
    "rows = rows[:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-stevens",
   "metadata": {},
   "source": [
    "#### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-writer",
   "metadata": {},
   "source": [
    "In this section I will perform several operations to clean the text data.  First, I will split each sequence into tokens by splitting at white spaces.  Next, I will remove punctuations and non-alphabetic characters.  Finally, I will convert all text to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "patent-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Split the text into tokens at white spaces\n",
    "    tokens = text.split()\n",
    "    # Use regex to filter for punctuation\n",
    "    no_punc = re.compile('[%s]'% re.escape(string.punctuation))\n",
    "    # Remove the punctuation\n",
    "    tokens = [no_punc.sub('', char) for char in tokens]\n",
    "    # Remove any tokens that are non-alphabetic \n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # Lowercase all text\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-maker",
   "metadata": {},
   "source": [
    "I will here split the data into the French phrases and the English, cleaning the text of each as I do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "royal-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "french = []\n",
    "english = []\n",
    "for row in rows:\n",
    "    french.append(clean_text(row[1]))\n",
    "    english.append(clean_text(row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-vertical",
   "metadata": {},
   "source": [
    "Before moving further I will take a look at the data to see if any rows need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mexican-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of the text\n",
    "df = pd.DataFrame()\n",
    "df['French'] = french\n",
    "df['English'] = english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "earned-domain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>French</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[va]</td>\n",
       "      <td>[go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[marche]</td>\n",
       "      <td>[go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bouge]</td>\n",
       "      <td>[go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[salut]</td>\n",
       "      <td>[hi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[salut]</td>\n",
       "      <td>[hi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[cours]</td>\n",
       "      <td>[run]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[courez]</td>\n",
       "      <td>[run]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[prenez, vos, jambes, à, vos, cous]</td>\n",
       "      <td>[run]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[file]</td>\n",
       "      <td>[run]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[filez]</td>\n",
       "      <td>[run]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                French English\n",
       "0                                 [va]    [go]\n",
       "1                             [marche]    [go]\n",
       "2                              [bouge]    [go]\n",
       "3                              [salut]    [hi]\n",
       "4                              [salut]    [hi]\n",
       "5                              [cours]   [run]\n",
       "6                             [courez]   [run]\n",
       "7  [prenez, vos, jambes, à, vos, cous]   [run]\n",
       "8                               [file]   [run]\n",
       "9                              [filez]   [run]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efficient-auction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>French</th>\n",
       "      <th>English</th>\n",
       "      <th>French Length</th>\n",
       "      <th>English Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[va]</td>\n",
       "      <td>[go]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[marche]</td>\n",
       "      <td>[go]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bouge]</td>\n",
       "      <td>[go]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[salut]</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[salut]</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[cours]</td>\n",
       "      <td>[run]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[courez]</td>\n",
       "      <td>[run]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[prenez, vos, jambes, à, vos, cous]</td>\n",
       "      <td>[run]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[file]</td>\n",
       "      <td>[run]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[filez]</td>\n",
       "      <td>[run]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                French English  French Length  English Length\n",
       "0                                 [va]    [go]              1               1\n",
       "1                             [marche]    [go]              1               1\n",
       "2                              [bouge]    [go]              1               1\n",
       "3                              [salut]    [hi]              1               1\n",
       "4                              [salut]    [hi]              1               1\n",
       "5                              [cours]   [run]              1               1\n",
       "6                             [courez]   [run]              1               1\n",
       "7  [prenez, vos, jambes, à, vos, cous]   [run]              6               1\n",
       "8                               [file]   [run]              1               1\n",
       "9                              [filez]   [run]              1               1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "df['French Length'] = df['French'].apply(lambda x: len(x))\n",
    "df['English Length'] = df['English'].apply(lambda x: len(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "arctic-blues",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     French            English  French Length  English Length\n",
      "468      []        [get, away]              0               2\n",
      "6133     []  [am, i, approved]              0               3\n",
      "Empty DataFrame\n",
      "Columns: [French, English, French Length, English Length]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for any missing rows\n",
    "empty_fr = df[df['French Length'] == 0]\n",
    "empty_eng = df[df['English Length'] == 0]\n",
    "\n",
    "print(empty_fr)\n",
    "print(empty_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "distant-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df = df[df['French Length'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-romantic",
   "metadata": {},
   "source": [
    "Next, I will split the text into the inputs, X, and outputs, y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sound-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['French'].values\n",
    "y = df['English'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-heath",
   "metadata": {},
   "source": [
    "#### Preparing French and English Tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-major",
   "metadata": {},
   "source": [
    "Next, I create two tokenizers - one for the English sequences and one for the French.  In this section I will save the vocabulary size (number of unique words) and the max sequence length for each of the two tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wanted-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the French tokenizer\n",
    "fra_tokenizer = Tokenizer()\n",
    "fra_tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pointed-breed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French vocabulary size: 12582\n"
     ]
    }
   ],
   "source": [
    "# Check the size of French vocabulary\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('French vocabulary size:', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "enormous-military",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French max length: 14\n"
     ]
    }
   ],
   "source": [
    "# Get the maximum length of a sequence\n",
    "fra_len = max(df['French Length'])\n",
    "print('French max length:', fra_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "peripheral-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the English tokenizer\n",
    "eng_tokenizer = Tokenizer()\n",
    "eng_tokenizer.fit_on_texts(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "smoking-helen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocabulary size: 5986\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the English vocabulary\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "print('English vocabulary size:', eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "political-stockholm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English max length: 7\n"
     ]
    }
   ],
   "source": [
    "# Get the maximum length of a sequence\n",
    "eng_len = max(df['English Length'])\n",
    "print('English max length:', eng_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-pointer",
   "metadata": {},
   "source": [
    "Next, I want to split the data into training and testing sets.  Then I want to convert the tokens into sequences and then pad each to match the maximum lenght.  For the output data, I want to use one-hot encoding to make these categorical.  To do these processes I will use two functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-defendant",
   "metadata": {},
   "source": [
    "#### Splitting into Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sticky-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "played-removal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X-train (39998,)\n",
      "Size of y-train (39998,)\n",
      "Size of X-test (10000,)\n",
      "Size of y-test (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Size of X-train', X_train.shape)\n",
    "print('Size of y-train', y_train.shape)\n",
    "print('Size of X-test', X_test.shape)\n",
    "print('Size of y-test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-scott",
   "metadata": {},
   "source": [
    "#### Encoding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "legendary-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequences(tokenizer, length, text_tokens):\n",
    "    \"\"\"\n",
    "    Here I will take the data that has been tokenized and convert the tokens\n",
    "    into integers, using the pre-fit tokenizer.  Then, I will pad the lengths \n",
    "    of each sequence to match the maximum length.\n",
    "    \"\"\"\n",
    "    # Encode sequences with integers\n",
    "    enc_seq = tokenizer.texts_to_sequences(text_tokens)\n",
    "    # Add 0's to the end of each to match the maximum length\n",
    "    enc_seq = pad_sequences(enc_seq, maxlen=length, padding='post')\n",
    "    return enc_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "collectible-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to enclode the X(French) and y(English) sequences\n",
    "X_train = encode_sequences(fra_tokenizer, fra_len, X_train)\n",
    "y_train = encode_sequences(eng_tokenizer, eng_len, y_train)\n",
    "\n",
    "X_test = encode_sequences(fra_tokenizer, fra_len, X_test)\n",
    "y_test = encode_sequences(eng_tokenizer, eng_len, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "gross-render",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X-train (39998, 14)\n",
      "Size of y-train (39998, 7)\n",
      "Size of X-test (10000, 14)\n",
      "Size of y-test (10000, 7)\n"
     ]
    }
   ],
   "source": [
    "print('Size of X-train', X_train.shape)\n",
    "print('Size of y-train', y_train.shape)\n",
    "print('Size of X-test', X_test.shape)\n",
    "print('Size of y-test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-psychiatry",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding Output Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "regional-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_output(sequences, vocab_size):\n",
    "    \"\"\"\n",
    "    One-hot encode the output (English sentences), using the to_categorical function\n",
    "    where the number of classes is equal to the English vocabulary size from the fit\n",
    "    tokenizer.  Then reshape as needed for use in the model.\n",
    "    \"\"\"\n",
    "    y_list = []\n",
    "    # Encode the sequences\n",
    "    for sequence in sequences:\n",
    "        one_hot = to_categorical(sequence, num_classes=vocab_size)\n",
    "        y_list.append(one_hot)\n",
    "    # Convert to numpy array\n",
    "    y = np.array(y_list)\n",
    "    # Reshape into three dimensions\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "respected-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to encode the ouput sequences\n",
    "y_train = encode_output(y_train, eng_vocab_size)\n",
    "y_test = encode_output(y_test, eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "catholic-blackjack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of y-train (39998, 7, 5986)\n",
      "Size of y-test (10000, 7, 5986)\n"
     ]
    }
   ],
   "source": [
    "print('Size of y-train', y_train.shape)\n",
    "print('Size of y-test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-crack",
   "metadata": {},
   "source": [
    "#### Building the Encoder-Decoder Architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-crawford",
   "metadata": {},
   "source": [
    "I am now ready to build the model.  By limiting the size of the dataset I am working with, I have a sequence-to-sequence problem where both the input and output sequences are short.  As such I will make use of the Encoder-Decorder architecture, using the Long Short-Term Memory (LSTM) model.  There are many other options I could have tried here - including RNN, bidirectional models, and GRUs, as well as adding an Attention Mechanism.  For now I will proceed with this relatively simple model and evaluate how it performs on this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "endless-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_vocab_size, output_vocab_size, input_seq_len, output_seq_len, mem_units):\n",
    "    \"\"\"\n",
    "    Encoder-Decoder using LSTM model for a many-to-many sequence-to-sequence problem.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_vocab_size, mem_units, input_length=input_seq_len))\n",
    "    model.add(LSTM(mem_units))\n",
    "    model.add(RepeatVector(output_seq_len))\n",
    "    model.add(LSTM(mem_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(output_vocab_size, activation='softmax')))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "center-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model \n",
    "model = define_model(fra_vocab_size, eng_vocab_size, fra_len, eng_len, 256)\n",
    "# Compile the model\n",
    "# By one-hot-encoding the targets this is a classification - so I use the Adam\n",
    "# optimizer and Categorical-crossentropy as the loss function \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "loved-bangkok",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 14, 256)           3220992   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 7, 256)            525312    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 7, 5986)           1538402   \n",
      "=================================================================\n",
      "Total params: 5,810,018\n",
      "Trainable params: 5,810,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-sunset",
   "metadata": {},
   "source": [
    "#### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fifteen-paris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 3.5148 - accuracy: 0.5030 - val_loss: 3.2799 - val_accuracy: 0.5120\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 3.2387 - accuracy: 0.5111 - val_loss: 3.2330 - val_accuracy: 0.5120\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 3.1970 - accuracy: 0.5112 - val_loss: 3.2139 - val_accuracy: 0.5120\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 84s 134ms/step - loss: 3.1769 - accuracy: 0.5112 - val_loss: 3.2088 - val_accuracy: 0.5120\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 3.1648 - accuracy: 0.5113 - val_loss: 3.2054 - val_accuracy: 0.5120\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 3.1572 - accuracy: 0.5112 - val_loss: 3.2042 - val_accuracy: 0.5120\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 3.1517 - accuracy: 0.5112 - val_loss: 3.2008 - val_accuracy: 0.5121\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 85s 135ms/step - loss: 3.1475 - accuracy: 0.5112 - val_loss: 3.2025 - val_accuracy: 0.5120\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 3.1440 - accuracy: 0.5113 - val_loss: 3.2008 - val_accuracy: 0.5120\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 3.1415 - accuracy: 0.5113 - val_loss: 3.2012 - val_accuracy: 0.5120\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 3.1734 - accuracy: 0.5098 - val_loss: 3.8431 - val_accuracy: 0.5072\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 3.3186 - accuracy: 0.5058 - val_loss: 3.2529 - val_accuracy: 0.5123\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 3.1007 - accuracy: 0.5224 - val_loss: 3.0933 - val_accuracy: 0.5279\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 2.9965 - accuracy: 0.5294 - val_loss: 3.0511 - val_accuracy: 0.5290\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 2.8925 - accuracy: 0.5380 - val_loss: 2.8756 - val_accuracy: 0.5522\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 2.7083 - accuracy: 0.5623 - val_loss: 2.7278 - val_accuracy: 0.5715\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 85s 137ms/step - loss: 2.4838 - accuracy: 0.5887 - val_loss: 2.5367 - val_accuracy: 0.5988\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 85s 137ms/step - loss: 2.2920 - accuracy: 0.6090 - val_loss: 2.4268 - val_accuracy: 0.6095\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 85s 137ms/step - loss: 2.1499 - accuracy: 0.6218 - val_loss: 2.3458 - val_accuracy: 0.6204\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 2.0218 - accuracy: 0.6345 - val_loss: 2.2721 - val_accuracy: 0.6288\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 86s 137ms/step - loss: 1.9599 - accuracy: 0.6428 - val_loss: 2.2359 - val_accuracy: 0.6352\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 1.8005 - accuracy: 0.6638 - val_loss: 2.0412 - val_accuracy: 0.6592\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 1.5938 - accuracy: 0.6871 - val_loss: 1.9475 - val_accuracy: 0.6704\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 1.4420 - accuracy: 0.7050 - val_loss: 1.8727 - val_accuracy: 0.6806\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 1.3088 - accuracy: 0.7222 - val_loss: 1.8093 - val_accuracy: 0.6887\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 1.1882 - accuracy: 0.7403 - val_loss: 1.7683 - val_accuracy: 0.6951\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 85s 136ms/step - loss: 1.0749 - accuracy: 0.7600 - val_loss: 1.7213 - val_accuracy: 0.7033\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 85s 137ms/step - loss: 0.9687 - accuracy: 0.7786 - val_loss: 1.6880 - val_accuracy: 0.7094\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 85s 137ms/step - loss: 0.8733 - accuracy: 0.7980 - val_loss: 1.6506 - val_accuracy: 0.7168\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 86s 137ms/step - loss: 0.7847 - accuracy: 0.8162 - val_loss: 1.6239 - val_accuracy: 0.7203\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 87s 138ms/step - loss: 0.7035 - accuracy: 0.8336 - val_loss: 1.6096 - val_accuracy: 0.7249\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.6301 - accuracy: 0.8490 - val_loss: 1.5883 - val_accuracy: 0.7311\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.5661 - accuracy: 0.8634 - val_loss: 1.5798 - val_accuracy: 0.7319\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.5092 - accuracy: 0.8761 - val_loss: 1.5690 - val_accuracy: 0.7372\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.4570 - accuracy: 0.8872 - val_loss: 1.5612 - val_accuracy: 0.7405\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 86s 138ms/step - loss: 0.4124 - accuracy: 0.8974 - val_loss: 1.5635 - val_accuracy: 0.7433\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.3721 - accuracy: 0.9061 - val_loss: 1.5642 - val_accuracy: 0.7453\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 87s 140ms/step - loss: 0.3375 - accuracy: 0.9138 - val_loss: 1.5654 - val_accuracy: 0.7464\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.3063 - accuracy: 0.9210 - val_loss: 1.5751 - val_accuracy: 0.7475\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.2807 - accuracy: 0.9266 - val_loss: 1.5803 - val_accuracy: 0.7488\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.2571 - accuracy: 0.9314 - val_loss: 1.5844 - val_accuracy: 0.7501\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 87s 140ms/step - loss: 0.2357 - accuracy: 0.9367 - val_loss: 1.6034 - val_accuracy: 0.7493\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 87s 140ms/step - loss: 0.2169 - accuracy: 0.9406 - val_loss: 1.5988 - val_accuracy: 0.7514\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.2015 - accuracy: 0.9436 - val_loss: 1.6082 - val_accuracy: 0.7506\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.1879 - accuracy: 0.9469 - val_loss: 1.6313 - val_accuracy: 0.7490\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 88s 140ms/step - loss: 0.1760 - accuracy: 0.9491 - val_loss: 1.6297 - val_accuracy: 0.7518\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 87s 140ms/step - loss: 0.1659 - accuracy: 0.9510 - val_loss: 1.6477 - val_accuracy: 0.7523\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 88s 141ms/step - loss: 0.1551 - accuracy: 0.9532 - val_loss: 1.6563 - val_accuracy: 0.7517\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 89s 142ms/step - loss: 0.1486 - accuracy: 0.9543 - val_loss: 1.6721 - val_accuracy: 0.7501\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 88s 140ms/step - loss: 0.1416 - accuracy: 0.9558 - val_loss: 1.6760 - val_accuracy: 0.7522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f9a18f0c70>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model \n",
    "# Store the history for evaluation purposes\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "linear-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the model history for plotting purposes\n",
    "histories = model.history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-astrology",
   "metadata": {},
   "source": [
    "#### Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-greeting",
   "metadata": {},
   "source": [
    "Next, I will visualize the training and testing accuracies and losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "regular-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(histories):\n",
    "    \"\"\"\n",
    "    Plot the accuracies and the categorical cross-entropy for training and testing, per epoch. \n",
    "    \"\"\"\n",
    "    # Convert to data frame for plotting purposes\n",
    "    losses = pd.DataFrame(histories)\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    # Plot the training and testing accuracy\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.plot(losses['accuracy'], label='Training')\n",
    "    ax1.plot(losses['val_accuracy'], label='Testing')\n",
    "    ax1.set_title('Accuracy')\n",
    "    ax1.legend()\n",
    "    # Plot the training and testing categorical cross-entropy\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.plot(losses['loss'], label='Training')\n",
    "    ax2.plot(losses['val_loss'], label='Testing')\n",
    "    ax2.set_title('Categorical Cross-Entropy')\n",
    "    ax2.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "opposite-referral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the accuracy and loss over the 30 epochs\n",
    "plot_training(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-alexandria",
   "metadata": {},
   "source": [
    "I can see that the accuracy steadily increases from about the 10th epoch on both the training and testing datasets, before levelling off between the 30th and 40th epochs.  In terms of the loss function, the categorical cross-entropy, it decreases steadily on the training data, but on the test data it levels off around the 30th epoch and then starts to rise very slightly after about the 40th epoch.  This is a sign that the model is beginning to overfit at this point and will probably become worse if trained further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sudden-cycling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 25ms/step - loss: 1.6760 - accuracy: 0.7522\n",
      "Categorical Cross-Entropy on Test Dataset: 1.676\n",
      "Accuracy on Test Dataset: 75.22 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "cce, acc = model.evaluate(X_test, y_test, verbose = 1)\n",
    "print('Categorical Cross-Entropy on Test Dataset: {:.3f}'.format(cce))\n",
    "print('Accuracy on Test Dataset: {:.2f} %'.format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-possibility",
   "metadata": {},
   "source": [
    "The model is performing pretty well on the heldout test dataset.  Next, I will check predictions on some of the training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-department",
   "metadata": {},
   "source": [
    "#### Examining the Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-triumph",
   "metadata": {},
   "source": [
    "To see how the model is performing, I will need to use the tokenizers to convert the encoded integers back into the words.  The tokenizers' word indexes are dictionaries, where each unique word is represented by an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "communist-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_word(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "continuing-liabilities",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   8,   15,   16,  322, 4957,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at X_train[0]\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ideal-vulnerability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'il a un nom commun'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the integers found in the encoded input back into words\n",
    "words = [int_to_word(x, fra_tokenizer) for x in X_train[0]]\n",
    "# Stop when None appears\n",
    "words = [word for word in words if word != None]\n",
    "# Join into a sentence\n",
    "' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-sapphire",
   "metadata": {},
   "source": [
    "Looking at the translation targets, the outputs were one-hot encoded with a vocabulary length of 5986, and each sequence was padded to a length of 7.  This means that the y-data will be 7 vectors, each of length 5986.  In each of these vectors there will be at most one 1, and the rest of the values will be 0 (there can be all 0s if the sequence does not contain the maximum 7 words).  So, by finding the index of this 1 we know the integer value for the word that exists in that place in the sequence, and with this we can extract the actual word from the tokenizer.\n",
    "\n",
    "When it comes to making new predictions, probabilities will be generated for each of the 5986 possible words, and so finding the highest value within each of the 7 vectors will result in getting the word that is predicted to be most probable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "falling-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at y_train[0]\n",
    "# For each of the 7 vectors, get the index of the highest value \n",
    "# This is the word that is predicted with the highest probability\n",
    "integers = [np.argmax(vector) for vector in y_train[0]]\n",
    "target = [] \n",
    "# For each of these, get the corresponding English word\n",
    "for i in integers:\n",
    "    word = int_to_word(i, eng_tokenizer)\n",
    "    # Stop when reaching None\n",
    "    if word is None:\n",
    "        break\n",
    "    target.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "supposed-queue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he has a common name'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join into a sentence\n",
    "' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "approved-february",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5799556e-09, 4.0273294e-06, 4.3033289e-11, ..., 1.2306751e-16,\n",
       "        2.4679802e-12, 3.4404245e-13],\n",
       "       [2.8297972e-11, 4.1107080e-11, 9.5728011e-16, ..., 3.6521611e-14,\n",
       "        6.1111407e-12, 1.4697639e-14],\n",
       "       [2.1003605e-07, 8.2900747e-10, 6.5587667e-13, ..., 4.3958184e-14,\n",
       "        9.1868223e-13, 4.3484318e-12],\n",
       "       ...,\n",
       "       [3.6281035e-03, 1.0436039e-10, 3.5773648e-11, ..., 2.4086630e-13,\n",
       "        2.8531240e-08, 2.4508446e-09],\n",
       "       [9.4950610e-01, 6.5370501e-13, 2.1242491e-10, ..., 1.5350155e-16,\n",
       "        1.4403184e-11, 2.1130122e-13],\n",
       "       [9.9413896e-01, 5.3204362e-14, 1.9782613e-12, ..., 1.1604215e-18,\n",
       "        8.9170961e-13, 8.9894599e-15]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions and getting the proper shape\n",
    "model.predict(X_train[0].reshape((1, X_train[0].shape[0])))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-cameroon",
   "metadata": {},
   "source": [
    "After reshaping, the predictions are of the shape (7, 5986).  As explained above, the index of the highest value in each of the rows will correspond with the index of the predicted word in the tokenizer vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "static-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation(text):\n",
    "    # Reshape text vector \n",
    "    text = text.reshape((1, text.shape[0]))\n",
    "    # Make prediction\n",
    "    prediction = model.predict(text, verbose=0)[0]\n",
    "    # Get the integer indexes of the predicted words\n",
    "    integers = [np.argmax(vector) for vector in prediction]\n",
    "    # Convert this into a text sequence\n",
    "    target = []\n",
    "    for i in integers:\n",
    "        word = int_to_word(i, eng_tokenizer)\n",
    "        # Stop when the sequence hits the None padding\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-frederick",
   "metadata": {},
   "source": [
    "I will write two functions here using the above code - one to take a row of the dataset and return the French sentence, and the second to take a row of the data and return the actual English translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "corresponding-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_french(row):\n",
    "    # Get the words from the tokenizer\n",
    "    words = [int_to_word(x, fra_tokenizer) for x in row]\n",
    "    # Stop when None appears\n",
    "    words = [word for word in words if word != None]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "german-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_english(row):\n",
    "    # Get word indexes\n",
    "    integers = [np.argmax(vector) for vector in row]\n",
    "    target = [] \n",
    "    for i in integers:\n",
    "        # Retrieve words from the tokenizer\n",
    "        word = int_to_word(i, eng_tokenizer)\n",
    "        # Stop when None is appears\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-oliver",
   "metadata": {},
   "source": [
    "#### Examining Some of the Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-sessions",
   "metadata": {},
   "source": [
    "I will get 10 random rows of the training data and compare the predicted translations to the actual translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "above-repository",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22107, 18698, 15303, 26214, 19771, 1947, 32859, 36168, 31964, 32038]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the indexes of the training input \n",
    "X_train_index = range(len(X_train))\n",
    "# Select 10 at random\n",
    "index = list(random.sample(X_train_index, 10))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "posted-klein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original French Sequence:  cest tout ce qua dit tom\n",
      "Actual English Translation:  thats all tom said\n",
      "Predicted English Translation:  thats all tom said\n",
      ".......................\n",
      "Original French Sequence:  jaime les fleurs des champs\n",
      "Actual English Translation:  i like wild flowers\n",
      "Predicted English Translation:  i like wild flowers\n",
      ".......................\n",
      "Original French Sequence:  cest terrifiant\n",
      "Actual English Translation:  its terrifying\n",
      "Predicted English Translation:  thats terrifying\n",
      ".......................\n",
      "Original French Sequence:  je veux les faits\n",
      "Actual English Translation:  i want the facts\n",
      "Predicted English Translation:  i want the facts\n",
      ".......................\n",
      "Original French Sequence:  cest tout ce que je fais ici\n",
      "Actual English Translation:  thats all i do here\n",
      "Predicted English Translation:  thats all i here here\n",
      ".......................\n",
      "Original French Sequence:  jespère seulement que tom va bien\n",
      "Actual English Translation:  i just hope tom is ok\n",
      "Predicted English Translation:  i hope hope tom is ok\n",
      ".......................\n",
      "Original French Sequence:  cest le chemin qui est direct\n",
      "Actual English Translation:  the path is direct\n",
      "Predicted English Translation:  the path is direct\n",
      ".......................\n",
      "Original French Sequence:  arrêtez de me harceler\n",
      "Actual English Translation:  stop harassing me\n",
      "Predicted English Translation:  stop harassing me\n",
      ".......................\n",
      "Original French Sequence:  je laime beaucoup\n",
      "Actual English Translation:  i like her very much\n",
      "Predicted English Translation:  i like her very much\n",
      ".......................\n",
      "Original French Sequence:  tom est un beau mec\n",
      "Actual English Translation:  tom is a handsome guy\n",
      "Predicted English Translation:  tom is a handsome guy\n",
      ".......................\n"
     ]
    }
   ],
   "source": [
    "# Compare the predictions to the actual translations\n",
    "for i in index:\n",
    "    print('Original French Sequence: ', get_french(X_train[i]))\n",
    "    print('Actual English Translation: ', get_english(y_train[i]))\n",
    "    print('Predicted English Translation: ', get_translation(X_train[i]))\n",
    "    print('.......................')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-harmony",
   "metadata": {},
   "source": [
    "Overall, on this random selection of the training data the predictions are extremely accurate and most are exactly correct.  There are a couple small variations (the word that's, in place of it's), and a situation where a word is incorrectly repeated (thats all i here here), but the model is performing very well on these.  Next, I will see how it performed on a random selection of the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-intensity",
   "metadata": {},
   "source": [
    "#### Examining Some of the Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "serial-reading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4774, 2625, 4009, 3353, 6631, 815, 3398, 567, 9637, 501]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_index = range(len(X_test))\n",
    "index2 = list(random.sample(X_test_index, 10))\n",
    "index2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fatal-newfoundland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original French Sequence:  tu as parfaitement raison\n",
      "Actual English Translation:  youre totally right\n",
      "Predicted English Translation:  youre quite right\n",
      ".......................\n",
      "Original French Sequence:  je nai pas dit ça\n",
      "Actual English Translation:  i didnt say that\n",
      "Predicted English Translation:  i didnt say that\n",
      ".......................\n",
      "Original French Sequence:  le train est en avance\n",
      "Actual English Translation:  the train is early\n",
      "Predicted English Translation:  the trains early\n",
      ".......................\n",
      "Original French Sequence:  cétait moins une\n",
      "Actual English Translation:  it was really close\n",
      "Predicted English Translation:  that was close\n",
      ".......................\n",
      "Original French Sequence:  estce un cerf\n",
      "Actual English Translation:  is it a deer\n",
      "Predicted English Translation:  is that a deer\n",
      ".......................\n",
      "Original French Sequence:  jexpliquerai\n",
      "Actual English Translation:  ill explain\n",
      "Predicted English Translation:  ill love\n",
      ".......................\n",
      "Original French Sequence:  je vous verrai tous demain\n",
      "Actual English Translation:  see you all tomorrow\n",
      "Predicted English Translation:  see you you tomorrow\n",
      ".......................\n",
      "Original French Sequence:  jétais préoccupé\n",
      "Actual English Translation:  i was worried\n",
      "Predicted English Translation:  i was concerned\n",
      ".......................\n",
      "Original French Sequence:  faites ce que vous voulez\n",
      "Actual English Translation:  just do what you want\n",
      "Predicted English Translation:  do what you want\n",
      ".......................\n",
      "Original French Sequence:  jai renversé ma boisson\n",
      "Actual English Translation:  i spilled my drink\n",
      "Predicted English Translation:  i stole my brother\n",
      ".......................\n"
     ]
    }
   ],
   "source": [
    "for i in index2:\n",
    "    print('Original French Sequence: ', get_french(X_test[i]))\n",
    "    print('Actual English Translation: ', get_english(y_test[i]))\n",
    "    print('Predicted English Translation: ', get_translation(X_test[i]))\n",
    "    print('.......................')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-ensemble",
   "metadata": {},
   "source": [
    "In this random selection there is quite a ranage in the accuracy of the predictions.  Some are exactly correct, some are mostly correct with some variation that still makes sense (for example, the word \"concerned\" being predicted instead of \"worried\"), and some are very, very wrong.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-leisure",
   "metadata": {},
   "source": [
    "Now I will show how the model and tokenizers can be saved and then loaded to make predictions on brand new French text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-produce",
   "metadata": {},
   "source": [
    "#### Saving the Model and Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "charming-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('fra_to_eng.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "brief-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizers\n",
    "pickle.dump(fra_tokenizer, open('fra_tokenizer.pkl', 'wb'))\n",
    "pickle.dump(eng_tokenizer, open('eng_tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-semester",
   "metadata": {},
   "source": [
    "#### Translating New French Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-handy",
   "metadata": {},
   "source": [
    "To use my model to translate new text, I will take French input, pre-process it following what I did with the data the model was trained on, and then follow the same steps as before - tokenizing, padding, and then predicting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-impact",
   "metadata": {},
   "source": [
    "Here I test a very simple input, \"Je suis heureux\", or, \"I am happy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "perceived-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fra_input = 'Je suis heureux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "broke-fiber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['je', 'suis', 'heureux']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text using the same function I used on the dataset\n",
    "clean_fra_input = clean_text(fra_input)\n",
    "clean_fra_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "missing-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizers\n",
    "fra_tokenizer = pickle.load(open('fra_tokenizer.pkl', 'rb'))\n",
    "eng_tokenizer = pickle.load(open('eng_tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-charlotte",
   "metadata": {},
   "source": [
    "As before, this input must be tokenized and padded to match the maximum length of the input (which was 14 words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "described-colony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [12], [159]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the French tokenizer to encode the input text \n",
    "encoded_input = fra_tokenizer.texts_to_sequences(clean_fra_input)\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-fifty",
   "metadata": {},
   "source": [
    "I want to convert this into a Numpy array, and pad its length to match the maximum French sequence length of 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "varying-commander",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 12, 159]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of the integers\n",
    "encoded_input = [i[0] for i in encoded_input]\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "marine-simon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  12, 159,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad with 0's until it matches the proper length of 14 tokens\n",
    "while len(encoded_input) < 14:\n",
    "    encoded_input.append(0)\n",
    "# Convert to a Numpy array\n",
    "encoded_input = np.array(encoded_input)\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-brighton",
   "metadata": {},
   "source": [
    "This now matches the training and testing data and is ready for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "coordinated-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model('fra_to_eng.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "sealed-premises",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im happy'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the translation\n",
    "translation = get_translation(encoded_input)\n",
    "translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-scanning",
   "metadata": {},
   "source": [
    "It works on this very very short and common phrase.  I will combined these steps now into a translation function to see how the model performs on various sorts of inputs.  This will be done in a standalone notebook.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-arthur",
   "metadata": {},
   "source": [
    "### *** Please see \"french_to_english.ipynb' that follows for the completition of my assignment submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-taylor",
   "metadata": {},
   "source": [
    "#### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-kitchen",
   "metadata": {},
   "source": [
    "My model performs well on the training data and input sequences that are short and common phrases (see the notebook that follows for further predictions on new text).  There is a lot of room for improvement here.  An attention mechanism is something that can be added to this model to make it better.  I can increase the depths of the encoder and decoder.  Also, I can make use of the concept of the beam search to improve the accuracy of the decoder. \n",
    "\n",
    "\n",
    "Furthermore, by limiting the dataset as I did at the outset of this notebook I am only training my model on short phrases.  This can be seen by the fact that the longest English phrase is only seven words long.  I can improve the model by increasing both the length and diversity of the training data sequences.  I notice that there are words, such as my name, Michael, for example, that do not exist in the training dataset.  Although this is a proper name, I would be interested to explore the tokenizer's vocabulary list further and see if there are further limitations in it.\n",
    "\n",
    "Overall, the model performs great on short and common phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-disorder",
   "metadata": {},
   "source": [
    "#### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-variable",
   "metadata": {},
   "source": [
    "Brownlee J.  How to Develop a Neural Machine Translation System from Scratch.  Machine Learning Mastery.  https://machinelearningmastery.com/develop-neural-machine-translation-system-keras/.  Published January 10, 2018.  Accessed March 23, 2021.\n",
    "\n",
    "Brownlee J.  How to Configure an Encoder-Decoder Model for Neural Machine Translation.  Machine Learning Mastery.  https://machinelearningmastery.com/configure-encoder-decoder-model-neural-machine-translation/.  Published January 3, 2018.  Accessed March 23, 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-stupid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
