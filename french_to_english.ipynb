{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "verified-yorkshire",
   "metadata": {},
   "source": [
    "## AIDI 2000 - Applied Machine Learning \n",
    "### Assignment 2 - Machine Translation\n",
    "\n",
    "#### Michael Molnar (100806823)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-cycle",
   "metadata": {},
   "source": [
    "This is the conclusion of my assignment.  In this notebook I will use my model to perform machine translation on user input French text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "convinced-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import pickle \n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-hundred",
   "metadata": {},
   "source": [
    "### Define Necessary Functions From Last Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greatest-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Preprocessing text.\n",
    "    \"\"\"\n",
    "    # Split the text into tokens at white spaces\n",
    "    tokens = text.split()\n",
    "    # Use regex to filter for punctuation\n",
    "    no_punc = re.compile('[%s]'% re.escape(string.punctuation))\n",
    "    # Remove the punctuation\n",
    "    tokens = [no_punc.sub('', char) for char in tokens]\n",
    "    # Remove any tokens that are non-alphabetic \n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # Lowercase all text\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "def int_to_word(integer, tokenizer):\n",
    "    \"\"\"\n",
    "    Converting encoded integer tokens back into words.\n",
    "    \"\"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "def get_translation(model, text, tokenizer):\n",
    "    \"\"\"\n",
    "    Translating cleaned and tokenized text from French to English.\n",
    "    \"\"\"\n",
    "    # Reshape text vector \n",
    "    text = text.reshape((1, text.shape[0]))\n",
    "    # Make prediction\n",
    "    prediction = model.predict(text, verbose=0)[0]\n",
    "    # Get the integer indexes of the predicted words\n",
    "    integers = [np.argmax(vector) for vector in prediction]\n",
    "    # Convert this into a text sequence\n",
    "    target = []\n",
    "    for i in integers:\n",
    "        word = int_to_word(i, tokenizer)\n",
    "        # Stop when the sequence hits the None padding\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-rouge",
   "metadata": {},
   "source": [
    "### Load the Model and the Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "historical-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model('fra_to_eng.h5')\n",
    "\n",
    "# Load the tokenizers\n",
    "fra_tokenizer = pickle.load(open('fra_tokenizer.pkl', 'rb'))\n",
    "eng_tokenizer = pickle.load(open('eng_tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-mileage",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pointed-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate():\n",
    "    # Get user's input\n",
    "    fra_input = input('Enter a French sentence: ')\n",
    "    # Clean the text\n",
    "    clean_fra_input = clean_text(fra_input)\n",
    "    # Use the French tokenizer to encode the input text \n",
    "    encoded_input = fra_tokenizer.texts_to_sequences(clean_fra_input)\n",
    "    # Create a list of integers\n",
    "    # NOTE:  some input words may not exist in the tokenizer's vocabulary\n",
    "    # if they did not appear in the training data\n",
    "    encoded_input = [i[0] for i in encoded_input if i]\n",
    "    # Pad with 0's until it matches the proper length of 14 tokens\n",
    "    while len(encoded_input) < 14:\n",
    "        encoded_input.append(0)\n",
    "    # Convert to a Numpy array\n",
    "    encoded_input = np.array(encoded_input)\n",
    "    # Get the translation\n",
    "    translation = get_translation(model, encoded_input, eng_tokenizer)\n",
    "    print('Predicted English translation:', translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-payday",
   "metadata": {},
   "source": [
    "#### Test 1 - \"Je suis heureux' ('I am happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "persistent-mount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a French sentence: Je suis heureux\n",
      "Predicted English translation: im happy\n"
     ]
    }
   ],
   "source": [
    "translate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-convention",
   "metadata": {},
   "source": [
    "#### Test 2 - 'Salut, mon nom est Michael' ('Hi, my name is Michael')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rural-style",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a French sentence: Salut, mon nom est Michael\n",
      "Predicted English translation: wheres is catch\n"
     ]
    }
   ],
   "source": [
    "translate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-conditioning",
   "metadata": {},
   "source": [
    "#### Test 3 - 'Il fait chaud aujourd'hui' ('It is hot today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "consolidated-chest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a French sentence: Il fait chaud aujourd'hui\n",
      "Predicted English translation: its is hot today\n"
     ]
    }
   ],
   "source": [
    "translate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-millennium",
   "metadata": {},
   "source": [
    "#### Test 4 - 'C'est marrant' ('This is fun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "female-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a French sentence: C'est marrant\n",
      "Predicted English translation: its fun\n"
     ]
    }
   ],
   "source": [
    "translate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-sugar",
   "metadata": {},
   "source": [
    "#### Test 5 - 'Ce ne fonctionne pas très bien' ('It doesn't work very well')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surprised-bowling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a French sentence: Ce ne fonctionne pas très bien\n",
      "Predicted English translation: this curry is very\n"
     ]
    }
   ],
   "source": [
    "translate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-bracelet",
   "metadata": {},
   "source": [
    "#### Test 6 - 'certains d'entre eux sont étranges' ('Some of them are weird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "italic-flood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a French sentence: certains d'entre eux sont étranges\n",
      "Predicted English translation: none of are died\n"
     ]
    }
   ],
   "source": [
    "translate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-picnic",
   "metadata": {},
   "source": [
    "#### Test 7 - 'Bonne journée' ('Have a nice day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "temporal-wilderness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a French sentence: Bonne journée\n",
      "Predicted English translation: have a nice day\n"
     ]
    }
   ],
   "source": [
    "translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-number",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
